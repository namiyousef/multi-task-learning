{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx0-RyBmMikb"
      },
      "source": [
        "# Flexible MTL design for testing different configurations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0w1DYWdOC6L"
      },
      "source": [
        "# Set up\n",
        "\n",
        "First, we need to clone the data. Instead of manually uploading, please clone the repository from Yipeng by running:\n",
        "\n",
        "`!git clone -b oxpet --single-branch https://weisslab.cs.ucl.ac.uk/WEISSTeaching/datasets.git`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01E9xLC4Mltp",
        "outputId": "7d88e502-f8a7-4f69-d5d4-726697c0a4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'datasets' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b oxpet --single-branch https://weisslab.cs.ucl.ac.uk/WEISSTeaching/datasets.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t64g4q99QyCD"
      },
      "source": [
        "Then, upload the `library.zip` file. This is a zipped version of the entire library, for is a manual process at the moment, until we work on a better way of exporting our library.\n",
        "\n",
        "Please not that torchvision.models.utils is not supported on the environment run here. A manual fix has been added to patch this. This should be visible when you run the code. Once uploaded, unzip the library using `unzip  library.zip`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRmGwjAzNSTm",
        "outputId": "dfb9399a-be0d-4f98-e634-107f2327d5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  flexible_mtl.zip\n",
            "  inflating: requirements.txt        \n",
            "  inflating: legacy/__init__.py      \n",
            "  inflating: legacy/utils.py         \n",
            "  inflating: legacy/train.py         \n",
            "  inflating: legacy/main.py          \n",
            "  inflating: legacy/models/bodys.py  \n",
            "  inflating: legacy/models/densenet.py  \n",
            "  inflating: legacy/models/__init__.py  \n",
            "  inflating: legacy/models/model.py  \n",
            "  inflating: legacy/models/resnet.py  \n",
            "  inflating: legacy/models/utils.py  \n",
            "  inflating: legacy/models/heads.py  \n",
            "  inflating: legacy/__pycache__/__init__.cpython-38.pyc  \n",
            "  inflating: legacy/__pycache__/train.cpython-38.pyc  \n",
            "  inflating: legacy/__pycache__/utils.cpython-38.pyc  \n",
            "  inflating: legacy/__pycache__/utils.cpython-37.pyc  \n",
            "  inflating: legacy/__pycache__/train.cpython-37.pyc  \n",
            "  inflating: legacy/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: legacy/criterion/loss_functions.py  \n",
            "  inflating: legacy/criterion/metric_functions.py  \n",
            "  inflating: legacy/criterion/criterion.py  \n",
            "  inflating: legacy/data/data.py     \n",
            "  inflating: legacy/models/__pycache__/__init__.cpython-38.pyc  \n",
            "  inflating: legacy/models/__pycache__/model.cpython-37.pyc  \n",
            "  inflating: legacy/models/__pycache__/utils.cpython-38.pyc  \n",
            "  inflating: legacy/models/__pycache__/heads.cpython-38.pyc  \n",
            "  inflating: legacy/models/__pycache__/resnet.cpython-38.pyc  \n",
            "  inflating: legacy/models/__pycache__/model.cpython-38.pyc  \n",
            "  inflating: legacy/models/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: legacy/models/__pycache__/bodys.cpython-38.pyc  \n",
            "  inflating: legacy/criterion/__pycache__/criterion.cpython-37.pyc  \n",
            "  inflating: legacy/criterion/__pycache__/metric_functions.cpython-38.pyc  \n",
            "  inflating: legacy/criterion/__pycache__/loss_functions.cpython-38.pyc  \n",
            "  inflating: legacy/criterion/__pycache__/metric_functions.cpython-37.pyc  \n",
            "  inflating: legacy/criterion/__pycache__/criterion.cpython-38.pyc  \n",
            "  inflating: legacy/data/__pycache__/data.cpython-38.pyc  \n",
            "  inflating: legacy/data/__pycache__/data.cpython-37.pyc  \n",
            "  inflating: models/bodys.py         \n",
            "  inflating: models/densenet.py      \n",
            "  inflating: models/__init__.py      \n",
            "  inflating: models/model.py         \n",
            "  inflating: models/resnet.py        \n",
            "  inflating: models/utils.py         \n",
            "  inflating: models/heads.py         \n",
            "  inflating: models/__pycache__/bodys.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/resnet.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/model.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/heads.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/utils.cpython-39.pyc  \n",
            "  inflating: models/__pycache__/utils.cpython-38.pyc  \n",
            "  inflating: models/__pycache__/heads.cpython-39.pyc  \n",
            "  inflating: models/__pycache__/heads.cpython-38.pyc  \n",
            "  inflating: models/__pycache__/utils.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/resnet.cpython-38.pyc  \n",
            "  inflating: models/__pycache__/resnet.cpython-39.pyc  \n",
            "  inflating: models/__pycache__/model.cpython-38.pyc  \n",
            "  inflating: models/__pycache__/model.cpython-39.pyc  \n",
            "  inflating: models/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/bodys.cpython-39.pyc  \n",
            "  inflating: models/__pycache__/bodys.cpython-38.pyc  \n",
            "  inflating: train.py                \n",
            "  inflating: criterion/loss_functions.py  \n",
            "  inflating: criterion/metric_functions.py  \n",
            "  inflating: criterion/__pycache__/metric_functions.cpython-38.pyc  \n",
            "  inflating: criterion/__pycache__/loss_functions.cpython-37.pyc  \n",
            "  inflating: criterion/__pycache__/loss_functions.cpython-38.pyc  \n",
            "  inflating: criterion/__pycache__/loss_functions.cpython-39.pyc  \n",
            "  inflating: criterion/__pycache__/metric_functions.cpython-37.pyc  \n",
            "  inflating: criterion/__pycache__/criterion.cpython-38.pyc  \n",
            "  inflating: data/data.py            \n",
            "  inflating: data/__pycache__/data.cpython-38.pyc  \n",
            "  inflating: data/__pycache__/data.cpython-39.pyc  \n",
            "  inflating: data/__pycache__/data.cpython-37.pyc  \n",
            "  inflating: main.py                 \n",
            "  inflating: tests/test_pt_continuous_train.py  \n",
            "  inflating: tests/test_get_prebuilts.py  \n",
            "  inflating: tests/test_loader.py    \n",
            "  inflating: tests/test_model_training_class.py  \n",
            "  inflating: utils.py                \n",
            "  inflating: __init__.py             \n",
            "  inflating: run.py                  \n"
          ]
        }
      ],
      "source": [
        "!unzip -o flexible_mtl.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62vB8MGvNmcR"
      },
      "source": [
        "Now we must install the relevant librries from the requirements file (this should be included in library.zip). Do this by running the following:\n",
        "`!python3 -m venv env`\n",
        "\n",
        "`!source env/bin/activate`\n",
        "\n",
        "`!pip install -r requirements.txt`\n",
        "\n",
        "You may get an error that the latest version of numpy could not be found. You can install this manually, although I believe it should exist by defualt in the first palce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjnJT1XgNwWk",
        "outputId": "8272486c-3433-4e17-bfda-54600412edee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['/content/mtl_test_colab/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "/bin/bash: mtl_test_colab/bin/activate: No such file or directory\n",
            "/usr/local/bin/python\n",
            "Requirement already satisfied: certifi==2021.10.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.0)\n",
            "Collecting fonttools==4.28.5\n",
            "  Using cached fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
            "Collecting h5py==3.6.0\n",
            "  Using cached h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Collecting imageio==2.13.5\n",
            "  Using cached imageio-2.13.5-py3-none-any.whl (3.3 MB)\n",
            "Requirement already satisfied: joblib==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: kiwisolver==1.3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.3.2)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Using cached matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Requirement already satisfied: networkx==2.6.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.6.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.22.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0, 1.13.1, 1.13.3, 1.14.0rc1, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0rc1, 1.17.0rc2, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0rc1, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0rc1, 1.19.0rc2, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0rc1, 1.20.0rc2, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0rc1, 1.21.0rc2, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for numpy==1.22.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m venv mtl_test_colab\n",
        "!source mtl_test_colab/bin/activate\n",
        "!which python\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLSmCgfNXTw"
      },
      "source": [
        "## Now... you design and run the model of your choice!\n",
        "\n",
        "```diff\n",
        "!PLEASE read before running \n",
        "```\n",
        "This notebook is different than the ones I've sent previously. The major difference is that it allows you to quickly and easily design the MTL model of your choice with ease, without needing to change the backend code. It also has added support for storing loss values, validation data, testing data and also the use of custom metrics and custom losses.\n",
        "\n",
        "Please note, it does NOT currently support saving and loading of models. That is a work in progress, but I've put it as a low priority task since it seems like our models are running quickly anyways. If there are urgent issues, then I will get it done ASAP.\n",
        "\n",
        "Please read the instructions here as they will give you a good understanding of how this is intended to be used. Run experiments on it, and if there are any issues notify me and create them on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "\n",
        "# GLOBALS\n",
        "\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "TEST_BATCH_SIZE = 8\n",
        "VAL_BATCH_SIZE = 8\n",
        "\n",
        "TASKS = ['seg', 'class', 'bb']"
      ],
      "metadata": {
        "id": "l-4FeuP30aAG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtnHty3dP6wP"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "It is good practice to always laod the data first. The dataloader has been modified to take in a path input from the user, to make it more flexible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4-0FdnAAPhwq"
      },
      "outputs": [],
      "source": [
        "## load data libraries\n",
        "from data.data import OxpetDataset, fast_loader\n",
        "\n",
        "## get your datasets\n",
        "\n",
        "data_path = 'datasets/data_new/' # point to the directory where the data sits\n",
        "trainset = OxpetDataset(data_path + 'train', TASKS)\n",
        "testset = OxpetDataset(data_path + 'test', TASKS)\n",
        "valset = OxpetDataset(data_path + 'val', TASKS)\n",
        "\n",
        "## define your dataloaders\n",
        "\n",
        "\n",
        "trainloader = fast_loader(trainset, batch_size=TRAIN_BATCH_SIZE)\n",
        "testloader = fast_loader(trainset, batch_size=TEST_BATCH_SIZE)\n",
        "valloader = fast_loader(trainset, batch_size=VAL_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XYZR54NRm8N"
      },
      "source": [
        "# Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uba1y1l4RmAB"
      },
      "outputs": [],
      "source": [
        "## imports\n",
        "from torch.optim import Adam\n",
        "from models.utils import get_prebuilt_model\n",
        "\n",
        "MODEL, LOSS = get_prebuilt_model('resnet34', decoders='+'.join(TASKS),\n",
        "                                 losses=f'DiceLoss+CrossEntropyLoss+{TRAIN_BATCH_SIZE/10000}*L1Loss', weights='uniform::1'\n",
        "                                 )\n",
        "OPTIMIZER = Adam(MODEL.parameters(), lr=1e-04)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from run import RunTorchModel\n",
        "from criterion.metric_functions import MultiAccuracy, PixelAccuracy, Recall, Precision, F1Score, Jaccard\n",
        "\n",
        "# initialise run, this is analogous to model.compile() in keras\n",
        "run_instance = RunTorchModel(\n",
        "    model=MODEL, optimizer=OPTIMIZER, loss=LOSS, metrics={\n",
        "        'class':[MultiAccuracy()],\n",
        "        'seg': [MultiAccuracy(), PixelAccuracy(), Recall(), Precision(), F1Score(), Jaccard()]\n",
        "        }\n",
        ")\n",
        "\n",
        "# training params\n",
        "EPOCHS=2\n",
        "VERBOSE=3\n",
        "TRACK_HISTORY=True # to save model hist\n",
        "\n",
        "run_instance.train(trainloader, valloader=valloader, epochs=EPOCHS, verbose=VERBOSE, track_history=TRACK_HISTORY) # analogous to model.fit() in keras\n",
        "run_instance.get_history() # training history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d7gADKH74jwv",
        "outputId": "3c61800c-a84a-45c7-e215-b06aa02a0c81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA device detected. Running on GPU.\n",
            "Training model...\n",
            "EPOCH 1 STARTED\n",
            "---------------\n",
            "Batch 1 complete. Time taken: load(0.377), train(0.443), total(0.82). \n",
            "RandomCombinedLoss(0.401), seg(0.154), class(0.206), bb(0.041)\n",
            "MultiAccuracy(3.14e+05), PixelAccuracy(0.506), Recall(0.637), Precision(0.424), F1Score(0.509), Jaccard(0.339)\n",
            "Batch 2 complete. Time taken: load(0.388), train(0.339), total(0.726). \n",
            "RandomCombinedLoss(0.432), seg(0.143), class(0.252), bb(0.0371)\n",
            "MultiAccuracy(3.14e+05), PixelAccuracy(0.498), Recall(0.657), Precision(0.421), F1Score(0.513), Jaccard(0.332)\n",
            "Batch 3 complete. Time taken: load(0.744), train(0.338), total(1.08). \n",
            "RandomCombinedLoss(0.436), seg(0.15), class(0.254), bb(0.0325)\n",
            "MultiAccuracy(3.2e+05), PixelAccuracy(0.474), Recall(0.657), Precision(0.396), F1Score(0.493), Jaccard(0.311)\n",
            "Batch 4 complete. Time taken: load(0.384), train(0.335), total(0.719). \n",
            "RandomCombinedLoss(0.468), seg(0.153), class(0.284), bb(0.0304)\n",
            "MultiAccuracy(3.22e+05), PixelAccuracy(0.46), Recall(0.669), Precision(0.387), F1Score(0.489), Jaccard(0.299)\n",
            "Batch 5 complete. Time taken: load(0.376), train(0.337), total(0.713). \n",
            "RandomCombinedLoss(0.456), seg(0.163), class(0.263), bb(0.0297)\n",
            "MultiAccuracy(3.24e+05), PixelAccuracy(0.455), Recall(0.686), Precision(0.383), F1Score(0.49), Jaccard(0.296)\n",
            "Batch 6 complete. Time taken: load(0.383), train(0.335), total(0.717). \n",
            "RandomCombinedLoss(0.451), seg(0.18), class(0.243), bb(0.0284)\n",
            "MultiAccuracy(3.31e+05), PixelAccuracy(0.454), Recall(0.72), Precision(0.377), F1Score(0.491), Jaccard(0.294)\n",
            "Batch 7 complete. Time taken: load(0.729), train(0.337), total(1.07). \n",
            "RandomCombinedLoss(0.442), seg(0.186), class(0.228), bb(0.0282)\n",
            "MultiAccuracy(3.34e+05), PixelAccuracy(0.447), Recall(0.735), Precision(0.37), F1Score(0.488), Jaccard(0.288)\n",
            "Batch 8 complete. Time taken: load(0.737), train(0.337), total(1.07). \n",
            "RandomCombinedLoss(0.44), seg(0.194), class(0.219), bb(0.0273)\n",
            "MultiAccuracy(3.36e+05), PixelAccuracy(0.439), Recall(0.745), Precision(0.365), F1Score(0.486), Jaccard(0.282)\n",
            "Batch 9 complete. Time taken: load(0.378), train(0.337), total(0.716). \n",
            "RandomCombinedLoss(0.442), seg(0.191), class(0.224), bb(0.0267)\n",
            "MultiAccuracy(3.31e+05), PixelAccuracy(0.446), Recall(0.76), Precision(0.377), F1Score(0.5), Jaccard(0.288)\n",
            "Batch 10 complete. Time taken: load(0.376), train(0.339), total(0.716). \n",
            "RandomCombinedLoss(0.428), seg(0.189), class(0.213), bb(0.0257)\n",
            "MultiAccuracy(3.27e+05), PixelAccuracy(0.457), Recall(0.777), Precision(0.389), F1Score(0.515), Jaccard(0.298)\n",
            "Batch 11 complete. Time taken: load(0.379), train(0.338), total(0.717). \n",
            "RandomCombinedLoss(0.424), seg(0.183), class(0.215), bb(0.0264)\n",
            "MultiAccuracy(3.23e+05), PixelAccuracy(0.461), Recall(0.787), Precision(0.396), F1Score(0.524), Jaccard(0.301)\n",
            "Batch 12 complete. Time taken: load(0.385), train(0.336), total(0.721). \n",
            "RandomCombinedLoss(0.42), seg(0.178), class(0.215), bb(0.027)\n",
            "MultiAccuracy(3.17e+05), PixelAccuracy(0.472), Recall(0.8), Precision(0.411), F1Score(0.54), Jaccard(0.311)\n",
            "Batch 13 complete. Time taken: load(0.38), train(0.338), total(0.718). \n",
            "RandomCombinedLoss(0.414), seg(0.173), class(0.214), bb(0.027)\n",
            "MultiAccuracy(3.2e+05), PixelAccuracy(0.473), Recall(0.815), Precision(0.409), F1Score(0.541), Jaccard(0.312)\n",
            "Batch 14 complete. Time taken: load(0.41), train(0.338), total(0.747). \n",
            "RandomCombinedLoss(0.419), seg(0.174), class(0.219), bb(0.0267)\n",
            "MultiAccuracy(3.18e+05), PixelAccuracy(0.482), Recall(0.825), Precision(0.417), F1Score(0.55), Jaccard(0.32)\n",
            "Batch 15 complete. Time taken: load(0.381), train(0.34), total(0.721). \n",
            "RandomCombinedLoss(0.411), seg(0.173), class(0.212), bb(0.0263)\n",
            "MultiAccuracy(3.21e+05), PixelAccuracy(0.486), Recall(0.834), Precision(0.417), F1Score(0.553), Jaccard(0.324)\n",
            "Batch 16 complete. Time taken: load(0.751), train(0.339), total(1.09). \n",
            "RandomCombinedLoss(0.406), seg(0.172), class(0.208), bb(0.0266)\n",
            "MultiAccuracy(3.21e+05), PixelAccuracy(0.493), Recall(0.84), Precision(0.421), F1Score(0.558), Jaccard(0.33)\n",
            "Batch 17 complete. Time taken: load(0.398), train(0.341), total(0.739). \n",
            "RandomCombinedLoss(0.408), seg(0.166), class(0.215), bb(0.0267)\n",
            "MultiAccuracy(3.21e+05), PixelAccuracy(0.502), Recall(0.845), Precision(0.427), F1Score(0.565), Jaccard(0.339)\n",
            "Batch 18 complete. Time taken: load(0.391), train(0.34), total(0.731). \n",
            "RandomCombinedLoss(0.408), seg(0.163), class(0.218), bb(0.0262)\n",
            "MultiAccuracy(3.19e+05), PixelAccuracy(0.513), Recall(0.849), Precision(0.437), F1Score(0.573), Jaccard(0.349)\n",
            "Batch 19 complete. Time taken: load(0.392), train(0.341), total(0.732). \n",
            "RandomCombinedLoss(0.396), seg(0.16), class(0.209), bb(0.0268)\n",
            "MultiAccuracy(3.15e+05), PixelAccuracy(0.525), Recall(0.849), Precision(0.452), F1Score(0.584), Jaccard(0.362)\n",
            "Batch 20 complete. Time taken: load(0.376), train(0.337), total(0.713). \n",
            "RandomCombinedLoss(0.399), seg(0.159), class(0.213), bb(0.0271)\n",
            "MultiAccuracy(3.15e+05), PixelAccuracy(0.532), Recall(0.849), Precision(0.457), F1Score(0.589), Jaccard(0.369)\n",
            "Batch 21 complete. Time taken: load(0.387), train(0.34), total(0.728). \n",
            "RandomCombinedLoss(0.399), seg(0.154), class(0.218), bb(0.0274)\n",
            "MultiAccuracy(3.12e+05), PixelAccuracy(0.542), Recall(0.851), Precision(0.469), F1Score(0.598), Jaccard(0.38)\n",
            "Batch 22 complete. Time taken: load(0.385), train(0.343), total(0.728). \n",
            "RandomCombinedLoss(0.397), seg(0.151), class(0.219), bb(0.0274)\n",
            "MultiAccuracy(3.13e+05), PixelAccuracy(0.549), Recall(0.852), Precision(0.473), F1Score(0.602), Jaccard(0.386)\n",
            "Batch 23 complete. Time taken: load(0.375), train(0.338), total(0.714). \n",
            "RandomCombinedLoss(0.395), seg(0.15), class(0.218), bb(0.0272)\n",
            "MultiAccuracy(3.11e+05), PixelAccuracy(0.557), Recall(0.851), Precision(0.483), F1Score(0.609), Jaccard(0.395)\n",
            "Batch 24 complete. Time taken: load(0.38), train(0.342), total(0.721). \n",
            "RandomCombinedLoss(0.392), seg(0.149), class(0.215), bb(0.0275)\n",
            "MultiAccuracy(3.11e+05), PixelAccuracy(0.561), Recall(0.851), Precision(0.485), F1Score(0.61), Jaccard(0.399)\n",
            "Batch 25 complete. Time taken: load(0.392), train(0.34), total(0.732). \n",
            "RandomCombinedLoss(0.402), seg(0.149), class(0.226), bb(0.0272)\n",
            "MultiAccuracy(3.12e+05), PixelAccuracy(0.565), Recall(0.851), Precision(0.486), F1Score(0.611), Jaccard(0.403)\n",
            "Batch 26 complete. Time taken: load(0.38), train(0.34), total(0.72). \n",
            "RandomCombinedLoss(0.406), seg(0.147), class(0.232), bb(0.0271)\n",
            "MultiAccuracy(3.11e+05), PixelAccuracy(0.57), Recall(0.849), Precision(0.492), F1Score(0.616), Jaccard(0.408)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-14649d495c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mTRACK_HISTORY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m# to save model hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrun_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRACK_HISTORY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# analogous to model.fit() in keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mrun_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/run.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainloader, epochs, valloader, verbose, track_history)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mepoch_train_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcreate_init_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_init_history\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_init_histories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mstart_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO need to test transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "flexible_mtl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}